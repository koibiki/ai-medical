{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengli/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from dateutil.parser import parse\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "from feature_engineering.nan_stastics import nan_statics\n",
    "from feature_engineering.rank_feature_majority import rank_feature_majority_all, rank_feature_majority_train_valid_test\n",
    "from feature_engineering.segment_raw_data import segment_raw_data\n",
    "from feature_engineering.rank_feature import rank_feature, rank_feature_by_max, rank_feature_count\n",
    "from model_selection.classifier_model_factory import ClassifierModelFactory\n",
    "from model_selection.regressor_model_factory import RegressorModelFactory\n",
    "from model_selection.multi_classifier_model_factory import MultiClassifierModelFactory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from model_selection.cv import k_fold_regressor, k_fold_classifier, create_sample_k_fold_regressor\n",
    "from sampling.sample import sample_by_test_scale, separate_high_median_normal, separate_high_normal\n",
    "from utils import create_scale_feature, normalize_data_frame, delete_error_data, filtration, create_sample, logloss_to_class, softmax_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/d_train_20180102.csv', encoding='gb2312')\n",
    "test = pd.read_csv('input/d_test_A_20180102.csv', encoding='gb2312')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.iloc[:, 1:-1]\n",
    "train_target = train.iloc[:, -1]\n",
    "test_data = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['性别'] = train_data['性别'].apply(lambda x:1 if x == '男' else 0)\n",
    "test_data['性别'] = test_data['性别'].apply(lambda x:1 if x == '男' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['体检日期'] = (pd.to_datetime(train_data['体检日期']) - parse('2016-10-09')).dt.days\n",
    "test_data['体检日期'] = (pd.to_datetime(test_data['体检日期']) - parse('2016-10-09')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train_data.columns\n",
    "str_columns = ['sex', 'age', 'date'] + ['f' + str(p) for p in range(len(columns)-3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = str_columns\n",
    "test_data.columns = str_columns\n",
    "train_target.name = 'Y'\n",
    "train_target_class = train_target.apply(lambda x: 1 if x > 7 else 0)\n",
    "train_target_class.name = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sum_feature(data):\n",
    "    new_data = data\n",
    "    columns = data.columns\n",
    "    for index in range(3, len(columns)-3):\n",
    "        for j in range(index + 1, len(columns)):\n",
    "            new_data.insert(new_data.shape[1], 'sum_' + columns[j] + '_' + columns[index], data.iloc[:, j] + data.iloc[:, index])\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_target = pd.concat([train_data, train_target, train_target_class], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data_target, train_target_class, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_data = X_valid.iloc[:, :-2]\n",
    "y_valid_data = X_valid.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "high, normal = separate_high_normal(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high_train_data = high.iloc[:,:-2]\n",
    "y_high_train_data = high.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal_train_data = normal.iloc[:,:-2]\n",
    "y_normal_train_data = normal.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_datas = [X_high_train_data] + [create_sample(X_high_train_data) for i in range(10)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_datas = [y_high_train_data for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = pd.concat(X_train_datas + [X_normal_train_data], axis=0).reset_index(drop=True)\n",
    "y_train_data = pd.concat(y_train_datas + [y_normal_train_data], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_test = pd.concat([X_train_data, X_valid_data, test_data], axis=0)\n",
    "train_valid_test, factors = normalize_data_frame(train_valid_test, start_index=2)\n",
    "X_train_data = train_valid_test.iloc[:X_train_data.shape[0]]\n",
    "X_valid_data = train_valid_test.iloc[X_train_data.shape[0]:(X_train_data.shape[0] + X_valid_data.shape[0])]\n",
    "test_data = train_valid_test.iloc[(X_train_data.shape[0] + X_valid_data.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:3035: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train_data.fillna(-99, inplace=True)\n",
    "X_valid_data.fillna(-99, inplace=True)\n",
    "test_data.fillna(-99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始CV 5折训练...\n",
      "第0次训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.42062\n",
      "[200]\tvalid_0's binary_logloss: 0.272338\n",
      "[300]\tvalid_0's binary_logloss: 0.195273\n",
      "[400]\tvalid_0's binary_logloss: 0.150385\n",
      "[500]\tvalid_0's binary_logloss: 0.12416\n",
      "[600]\tvalid_0's binary_logloss: 0.107119\n",
      "[700]\tvalid_0's binary_logloss: 0.0959359\n",
      "[800]\tvalid_0's binary_logloss: 0.0885029\n",
      "[900]\tvalid_0's binary_logloss: 0.0825481\n",
      "[1000]\tvalid_0's binary_logloss: 0.0779164\n",
      "[1100]\tvalid_0's binary_logloss: 0.0741258\n",
      "[1200]\tvalid_0's binary_logloss: 0.0714769\n",
      "[1300]\tvalid_0's binary_logloss: 0.0695329\n",
      "[1400]\tvalid_0's binary_logloss: 0.0679216\n",
      "[1500]\tvalid_0's binary_logloss: 0.0669975\n",
      "[1600]\tvalid_0's binary_logloss: 0.0660671\n",
      "[1700]\tvalid_0's binary_logloss: 0.0655338\n",
      "[1800]\tvalid_0's binary_logloss: 0.065476\n",
      "[1900]\tvalid_0's binary_logloss: 0.0653766\n",
      "[2000]\tvalid_0's binary_logloss: 0.0649009\n",
      "[2100]\tvalid_0's binary_logloss: 0.0648768\n",
      "[2200]\tvalid_0's binary_logloss: 0.0646692\n",
      "[2300]\tvalid_0's binary_logloss: 0.0644675\n",
      "[2400]\tvalid_0's binary_logloss: 0.0645801\n",
      "Early stopping, best iteration is:\n",
      "[2351]\tvalid_0's binary_logloss: 0.0643759\n",
      "第1次训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.425387\n",
      "[200]\tvalid_0's binary_logloss: 0.279543\n",
      "[300]\tvalid_0's binary_logloss: 0.205109\n",
      "[400]\tvalid_0's binary_logloss: 0.169114\n",
      "[500]\tvalid_0's binary_logloss: 0.144161\n",
      "[600]\tvalid_0's binary_logloss: 0.128857\n",
      "[700]\tvalid_0's binary_logloss: 0.118104\n",
      "[800]\tvalid_0's binary_logloss: 0.110296\n",
      "[900]\tvalid_0's binary_logloss: 0.104598\n",
      "[1000]\tvalid_0's binary_logloss: 0.100392\n",
      "[1100]\tvalid_0's binary_logloss: 0.0976002\n",
      "[1200]\tvalid_0's binary_logloss: 0.0955217\n",
      "[1300]\tvalid_0's binary_logloss: 0.093834\n",
      "[1400]\tvalid_0's binary_logloss: 0.0925118\n",
      "[1500]\tvalid_0's binary_logloss: 0.0919054\n",
      "[1600]\tvalid_0's binary_logloss: 0.0916755\n",
      "[1700]\tvalid_0's binary_logloss: 0.0914821\n",
      "Early stopping, best iteration is:\n",
      "[1679]\tvalid_0's binary_logloss: 0.0913764\n",
      "第2次训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.43005\n",
      "[200]\tvalid_0's binary_logloss: 0.291598\n",
      "[300]\tvalid_0's binary_logloss: 0.21481\n",
      "[400]\tvalid_0's binary_logloss: 0.170366\n",
      "[500]\tvalid_0's binary_logloss: 0.141334\n",
      "[600]\tvalid_0's binary_logloss: 0.124273\n",
      "[700]\tvalid_0's binary_logloss: 0.112265\n",
      "[800]\tvalid_0's binary_logloss: 0.104158\n",
      "[900]\tvalid_0's binary_logloss: 0.0981835\n",
      "[1000]\tvalid_0's binary_logloss: 0.0938369\n",
      "[1100]\tvalid_0's binary_logloss: 0.0903407\n",
      "[1200]\tvalid_0's binary_logloss: 0.0876678\n",
      "[1300]\tvalid_0's binary_logloss: 0.0852897\n",
      "[1400]\tvalid_0's binary_logloss: 0.0839439\n",
      "[1500]\tvalid_0's binary_logloss: 0.0829031\n",
      "[1600]\tvalid_0's binary_logloss: 0.0822733\n",
      "[1700]\tvalid_0's binary_logloss: 0.0817764\n",
      "[1800]\tvalid_0's binary_logloss: 0.0814726\n",
      "[1900]\tvalid_0's binary_logloss: 0.0814146\n",
      "Early stopping, best iteration is:\n",
      "[1873]\tvalid_0's binary_logloss: 0.0813173\n",
      "第3次训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.428875\n",
      "[200]\tvalid_0's binary_logloss: 0.293347\n",
      "[300]\tvalid_0's binary_logloss: 0.217128\n",
      "[400]\tvalid_0's binary_logloss: 0.172337\n",
      "[500]\tvalid_0's binary_logloss: 0.145243\n",
      "[600]\tvalid_0's binary_logloss: 0.12806\n",
      "[700]\tvalid_0's binary_logloss: 0.116889\n",
      "[800]\tvalid_0's binary_logloss: 0.108604\n",
      "[900]\tvalid_0's binary_logloss: 0.102206\n",
      "[1000]\tvalid_0's binary_logloss: 0.0976787\n",
      "[1100]\tvalid_0's binary_logloss: 0.094044\n",
      "[1200]\tvalid_0's binary_logloss: 0.0918765\n",
      "[1300]\tvalid_0's binary_logloss: 0.0897141\n",
      "[1400]\tvalid_0's binary_logloss: 0.0886422\n",
      "[1500]\tvalid_0's binary_logloss: 0.0875647\n",
      "[1600]\tvalid_0's binary_logloss: 0.0871433\n",
      "[1700]\tvalid_0's binary_logloss: 0.0870709\n",
      "Early stopping, best iteration is:\n",
      "[1660]\tvalid_0's binary_logloss: 0.0868495\n",
      "第4次训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.433427\n",
      "[200]\tvalid_0's binary_logloss: 0.28891\n",
      "[300]\tvalid_0's binary_logloss: 0.20811\n",
      "[400]\tvalid_0's binary_logloss: 0.165884\n",
      "[500]\tvalid_0's binary_logloss: 0.141044\n",
      "[600]\tvalid_0's binary_logloss: 0.125111\n",
      "[700]\tvalid_0's binary_logloss: 0.113814\n",
      "[800]\tvalid_0's binary_logloss: 0.105189\n",
      "[900]\tvalid_0's binary_logloss: 0.0986834\n",
      "[1000]\tvalid_0's binary_logloss: 0.0938721\n",
      "[1100]\tvalid_0's binary_logloss: 0.0901587\n",
      "[1200]\tvalid_0's binary_logloss: 0.0872451\n",
      "[1300]\tvalid_0's binary_logloss: 0.0850287\n",
      "[1400]\tvalid_0's binary_logloss: 0.08354\n",
      "[1500]\tvalid_0's binary_logloss: 0.0826034\n",
      "[1600]\tvalid_0's binary_logloss: 0.0821709\n",
      "[1700]\tvalid_0's binary_logloss: 0.081653\n",
      "[1800]\tvalid_0's binary_logloss: 0.081394\n",
      "[1900]\tvalid_0's binary_logloss: 0.0811683\n",
      "[2000]\tvalid_0's binary_logloss: 0.0808925\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's binary_logloss: 0.0808873\n",
      "light_gbm_c_ k fold validation: 0.966188252705\n"
     ]
    }
   ],
   "source": [
    "lgb_y_valid, kf_lgb_mse = \\\n",
    "    k_fold_classifier(X_train_data, y_train_data, X_valid_data, ClassifierModelFactory.MODEL_LIGHET_GBM, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logloss_to_class(lgb_y_valid, class_level=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      1039\n",
      "          1       0.46      0.12      0.19        90\n",
      "\n",
      "avg / total       0.89      0.92      0.90      1129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid_data, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.Series(y_valid, name='valid').reset_index(drop=True)\n",
    "pred = pd.Series(y_pred, name='pred').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['valid']==1).values & (df['pred']==1).values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = df[(df['valid']==1).values & (df['pred']==0).values].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9.19\n",
       "8        9.85\n",
       "22      13.59\n",
       "45       8.76\n",
       "55       7.02\n",
       "76       9.38\n",
       "85      10.55\n",
       "89       7.61\n",
       "122      8.45\n",
       "125     13.13\n",
       "131      8.66\n",
       "167      7.02\n",
       "179      9.11\n",
       "184      9.43\n",
       "187      7.22\n",
       "227      8.41\n",
       "231      9.63\n",
       "238      7.91\n",
       "240      8.56\n",
       "251      7.54\n",
       "291      7.18\n",
       "310      7.24\n",
       "374     15.62\n",
       "380      7.03\n",
       "387      7.36\n",
       "392      8.31\n",
       "398     11.91\n",
       "412      7.54\n",
       "426      7.14\n",
       "428      8.75\n",
       "        ...  \n",
       "722      8.74\n",
       "723      7.10\n",
       "749      7.60\n",
       "751      9.37\n",
       "765     10.88\n",
       "774     17.41\n",
       "795      9.52\n",
       "818      8.83\n",
       "825      8.22\n",
       "843     11.05\n",
       "845      7.09\n",
       "851      8.06\n",
       "908      7.67\n",
       "918     10.02\n",
       "945     12.90\n",
       "948      7.28\n",
       "966      7.05\n",
       "976      8.28\n",
       "992      7.19\n",
       "997     11.82\n",
       "1004    11.09\n",
       "1017    10.21\n",
       "1056     9.24\n",
       "1063    10.55\n",
       "1075    10.01\n",
       "1080     7.89\n",
       "1097     7.06\n",
       "1098     7.01\n",
       "1116    13.81\n",
       "1127    13.98\n",
       "Name: Y, Length: 79, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.iloc[:,-2].reset_index(drop=True)[indexs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
