{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengli/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from model_selection.classifier_model_factory import ClassifierModelFactory\n",
    "from model_selection.multi_classifier_model_factory import MultiClassifierModelFactory\n",
    "from model_selection.cv import k_fold_classifier\n",
    "from model_selection.cv import logloss_2_class\n",
    "from sampling.sample import separate_high_normal\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from utils import create_scale_feature, normalize_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/d_train_20180102.csv', encoding='gb2312')\n",
    "test = pd.read_csv('input/d_test_A_20180102.csv', encoding='gb2312')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[:, 1:]\n",
    "test = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['性别'] = train['性别'].apply(lambda x: 1 if (x == '男') else 0)\n",
    "test['性别'] = test['性别'].apply(lambda x: 1 if (x == '男') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['体检日期'] = (pd.to_datetime(train['体检日期']) - parse('2016-10-09')).dt.days\n",
    "test['体检日期'] = (pd.to_datetime(test['体检日期']) - parse('2016-10-09')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train.columns\n",
    "str_columns = ['sex', 'age', 'date'] + ['f' + str(p) for p in range(len(columns)-4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = str_columns + ['Y']\n",
    "test.columns = str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([train.iloc[:, :-1], test], axis=0)\n",
    "\n",
    "train_test, factors = normalize_data_frame(train_test, start_index=2)\n",
    "train_data = train_test.iloc[:train.shape[0]]\n",
    "test_data = train_test.iloc[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_y(x):\n",
    "    if x < 6.1:\n",
    "        return 0\n",
    "    elif (x >= 6.1) & (x < 7):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train['Y']\n",
    "train_target_class = train['Y'].apply(lambda x : class_y(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.fillna(-99, inplace=True)\n",
    "# test_data.fillna(-99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, train_target, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/home/chengli/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTETomek()\n",
    "X_resampled, y_resampled = sm.fit_sample(X_train, y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_resampled, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.Series(y_resampled, name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始CV 5折训练...\n",
      "第0次训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.444768\n",
      "[200]\tvalid_0's binary_logloss: 0.388747\n",
      "[300]\tvalid_0's binary_logloss: 0.372598\n",
      "[400]\tvalid_0's binary_logloss: 0.369138\n",
      "[500]\tvalid_0's binary_logloss: 0.367736\n",
      "[600]\tvalid_0's binary_logloss: 0.368973\n",
      "Early stopping, best iteration is:\n",
      "[536]\tvalid_0's binary_logloss: 0.367092\n",
      "第1次训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.439819\n",
      "[200]\tvalid_0's binary_logloss: 0.380813\n",
      "[300]\tvalid_0's binary_logloss: 0.36449\n",
      "[400]\tvalid_0's binary_logloss: 0.359719\n",
      "[500]\tvalid_0's binary_logloss: 0.357582\n",
      "[600]\tvalid_0's binary_logloss: 0.357897\n",
      "Early stopping, best iteration is:\n",
      "[523]\tvalid_0's binary_logloss: 0.357385\n",
      "第2次训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.433535\n",
      "[200]\tvalid_0's binary_logloss: 0.371166\n",
      "[300]\tvalid_0's binary_logloss: 0.352595\n",
      "[400]\tvalid_0's binary_logloss: 0.34687\n",
      "[500]\tvalid_0's binary_logloss: 0.346117\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's binary_logloss: 0.345625\n",
      "第3次训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.446771\n",
      "[200]\tvalid_0's binary_logloss: 0.391622\n",
      "[300]\tvalid_0's binary_logloss: 0.375963\n",
      "[400]\tvalid_0's binary_logloss: 0.37278\n",
      "[500]\tvalid_0's binary_logloss: 0.372587\n",
      "[600]\tvalid_0's binary_logloss: 0.373344\n",
      "Early stopping, best iteration is:\n",
      "[510]\tvalid_0's binary_logloss: 0.372333\n",
      "第4次训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.445969\n",
      "[200]\tvalid_0's binary_logloss: 0.389743\n",
      "[300]\tvalid_0's binary_logloss: 0.374842\n",
      "[400]\tvalid_0's binary_logloss: 0.370521\n",
      "[500]\tvalid_0's binary_logloss: 0.371316\n",
      "Early stopping, best iteration is:\n",
      "[432]\tvalid_0's binary_logloss: 0.370206\n",
      "as: 0.8448895404085421\n"
     ]
    }
   ],
   "source": [
    "lgb_y_valid, kf_lgb_as = \\\n",
    "    k_fold_classifier(X_train, y_train, X_valid, ClassifierModelFactory.MODEL_LIGHET_GBM, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logloss_2_class(lgb_y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3796    1\n",
       "3105    0\n",
       "674     0\n",
       "2237    0\n",
       "3629    1\n",
       "3800    0\n",
       "5326    0\n",
       "66      0\n",
       "1678    1\n",
       "5152    0\n",
       "3455    0\n",
       "5139    0\n",
       "1708    0\n",
       "2555    0\n",
       "5109    0\n",
       "5618    0\n",
       "5229    0\n",
       "5000    0\n",
       "3727    1\n",
       "1198    0\n",
       "106     0\n",
       "731     0\n",
       "1849    1\n",
       "4675    1\n",
       "3659    0\n",
       "5574    0\n",
       "4723    1\n",
       "4298    0\n",
       "4005    0\n",
       "797     0\n",
       "       ..\n",
       "5341    0\n",
       "2397    1\n",
       "5544    0\n",
       "3643    0\n",
       "398     0\n",
       "3356    0\n",
       "963     1\n",
       "5095    0\n",
       "2064    0\n",
       "3474    0\n",
       "3883    0\n",
       "977     0\n",
       "421     0\n",
       "987     0\n",
       "1080    0\n",
       "2828    0\n",
       "105     0\n",
       "3478    1\n",
       "36      0\n",
       "5196    0\n",
       "1704    1\n",
       "3674    0\n",
       "3907    0\n",
       "598     0\n",
       "440     0\n",
       "1885    0\n",
       "463     0\n",
       "4715    0\n",
       "443     1\n",
       "1328    0\n",
       "Name: Y, Length: 1129, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.91       941\n",
      "          1       0.68      0.14      0.23       188\n",
      "\n",
      "avg / total       0.82      0.85      0.80      1129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred , target_names=['0','1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.DataFrame(pd.Series(y_pred, name='pred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['valid'] = y_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ss[(ss['pred'] == 1).values & (ss['valid'] == 0).values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(a1 == np.max(a1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = [1, 2,1,3]\n",
    "a2 = [2, 1, 0,3]\n",
    "a3 = [2, 1,1,0]\n",
    "ss = [a1, a2, a3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_2_class(data):\n",
    "    classes = []\n",
    "    for index in range(len(data)):\n",
    "        max_index = np.where(data[index] == np.max(data[index]))[0][0]\n",
    "        classes.append(max_index)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_2_class(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
